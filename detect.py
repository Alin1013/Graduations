import numpy as np
from PIL import Image
from get_yaml import get_config
import os
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings

# å¿½ç•¥æ— å…³è­¦å‘Š
warnings.filterwarnings('ignore')

from yolo import YOLO


# -------------------------- æ–°å¢ï¼šYOLO TXTæ ‡æ³¨ç”Ÿæˆå‡½æ•° --------------------------
def generate_yolo_txt(boxes, img_size, save_path, img_name):
    """
    ç”ŸæˆYOLOæ ¼å¼çš„TXTæ ‡æ³¨æ–‡ä»¶ï¼ˆæ›¿ä»£åŸXMLç”Ÿæˆï¼‰
    :param boxes: æ£€æµ‹æ¡†åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(label, ymin, xmin, ymax, xmax), ...]
    :param img_size: å›¾åƒå°ºå¯¸ (width, height)
    :param save_path: æ ‡æ³¨ä¿å­˜æ ¹ç›®å½•
    :param img_name: å›¾åƒæ–‡ä»¶åï¼ˆä¸å«åç¼€ï¼‰
    """
    os.makedirs(save_path, exist_ok=True)
    txt_path = os.path.join(save_path, f"{img_name}.txt")

    # è·å–ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®æ–‡ä»¶åŠ è½½ï¼‰
    config = get_config()
    class_names = config['names']
    class2id = {name: idx for idx, name in enumerate(class_names)}

    with open(txt_path, 'w', encoding='utf-8') as f:
        for box in boxes:
            try:
                label, ymin, xmin, ymax, xmax = box

                # è¿‡æ»¤æ— æ•ˆç±»åˆ«
                if label not in class2id:
                    print(f"âš ï¸  æœªçŸ¥ç±»åˆ« {label}ï¼Œè·³è¿‡è¯¥æ¡†")
                    continue

                # è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼ˆå½’ä¸€åŒ–ä¸­å¿ƒåæ ‡+å®½é«˜ï¼‰
                img_w, img_h = img_size
                x_center = (xmin + xmax) / 2 / img_w
                y_center = (ymin + ymax) / 2 / img_h
                width = (xmax - xmin) / img_w
                height = (ymax - ymin) / img_h

                # æ ¡éªŒåæ ‡æœ‰æ•ˆæ€§
                if x_center < 0 or x_center > 1 or y_center < 0 or y_center > 1:
                    print(f"âš ï¸  åæ ‡è¶Šç•Œï¼Œè·³è¿‡è¯¥æ¡†ï¼š{box}")
                    continue
                if width <= 0 or height <= 0 or width > 1 or height > 1:
                    print(f"âš ï¸  å®½é«˜æ— æ•ˆï¼Œè·³è¿‡è¯¥æ¡†ï¼š{box}")
                    continue

                # å†™å…¥TXTï¼ˆä¿ç•™6ä½å°æ•°ï¼‰
                cls_id = class2id[label]
                f.write(f"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
            except Exception as e:
                print(f"âš ï¸  å¤„ç†æ¡† {box} å¤±è´¥ï¼š{e}ï¼Œè·³è¿‡")
                continue

    if os.path.getsize(txt_path) == 0:
        # åˆ é™¤ç©ºæ ‡æ³¨æ–‡ä»¶
        os.remove(txt_path)
        print(f"âš ï¸  {img_name}.txt æ— æœ‰æ•ˆæ ‡æ³¨ï¼Œå·²åˆ é™¤")
    else:
        print(f"âœ… ç”Ÿæˆæ ‡æ³¨ï¼š{txt_path}")


# -------------------------- ä¼˜åŒ–ï¼šæ³¨æ„åŠ›å¯è§†åŒ–å‡½æ•° --------------------------
def visualize_attention(yolo_model, image, save_dir="attention_maps"):
    """
    ä¼˜åŒ–ç‰ˆæ³¨æ„åŠ›å¯è§†åŒ–ï¼ˆé€‚é…YOLOv8ï¼Œå…¼å®¹æ›´å¤šæ¨¡å‹ç»“æ„ï¼‰
    :param yolo_model: YOLOæ¨¡å‹å®ä¾‹
    :param image: PILå›¾åƒå¯¹è±¡
    :param save_dir: æ³¨æ„åŠ›å›¾ä¿å­˜ç›®å½•
    """
    os.makedirs(save_dir, exist_ok=True)
    attention_maps = []
    hooks = []

    # å®šä¹‰é€šç”¨é’©å­å‡½æ•°
    def hook_fn(module, input, output):
        if isinstance(output, torch.Tensor):
            attention_maps.append(output)
        elif isinstance(output, (tuple, list)):
            # å¤„ç†å¤šè¾“å‡ºæ¨¡å—
            for out in output:
                if isinstance(out, torch.Tensor):
                    attention_maps.append(out)

    # -------------------------- é€‚é…YOLOv8çš„æ³¨æ„åŠ›æ¨¡å—æ³¨å†Œ --------------------------
    try:
        # æ–¹æ¡ˆ1ï¼šé€‚é…YOLOv8 Neckï¼ˆPAN-FPNï¼‰ä¸­çš„æ³¨æ„åŠ›æ¨¡å—
        if hasattr(yolo_model.model, 'model'):
            # YOLOv8æ¨¡å‹ç»“æ„ï¼šmodel.modelæ˜¯æ ¸å¿ƒç½‘ç»œ
            for idx, module in enumerate(yolo_model.model.model):
                # æŸ¥æ‰¾åŒ…å«CBAM/æ³¨æ„åŠ›çš„æ¨¡å—ï¼ˆæ”¯æŒå¤šç§å‘½åï¼‰
                module_name = str(module).lower()
                if any(key in module_name for key in ['cbam', 'attention', 'eca']):
                    hook = module.register_forward_hook(hook_fn)
                    hooks.append(hook)
                    print(f"ğŸ“Œ ä¸ºæ¨¡å— {idx} ({module.__class__.__name__}) æ³¨å†Œæ³¨æ„åŠ›é’©å­")

        # æ–¹æ¡ˆ2ï¼šå…¼å®¹æ—§ç‰ˆPANetç»“æ„
        if not hooks and hasattr(yolo_model.model, 'neck'):
            neck = yolo_model.model.neck
            for name, module in neck.named_modules():
                if 'cbam' in name.lower() or 'attention' in name.lower():
                    hook = module.register_forward_hook(hook_fn)
                    hooks.append(hook)
                    print(f"ğŸ“Œ ä¸ºNeckæ¨¡å— {name} æ³¨å†Œæ³¨æ„åŠ›é’©å­")

        if not hooks:
            print("âš ï¸  æœªæ£€æµ‹åˆ°æ³¨æ„åŠ›æ¨¡å—ï¼Œè·³è¿‡æ³¨æ„åŠ›å¯è§†åŒ–")
            return

    except AttributeError as e:
        print(f"âš ï¸  æ³¨å†Œæ³¨æ„åŠ›é’©å­å¤±è´¥: {e}")
        return

    # -------------------------- å›¾åƒé¢„å¤„ç†ï¼ˆé€‚é…YOLOv8ï¼‰ --------------------------
    try:
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        img_np = np.array(image.convert('RGB'))  # ç¡®ä¿RGBæ ¼å¼
        # å½’ä¸€åŒ– + è½¬Tensor + æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0).to(yolo_model.device)

        # å‰å‘ä¼ æ’­è§¦å‘é’©å­
        with torch.no_grad():
            yolo_model.model(img_tensor)

        # -------------------------- ä¿å­˜æ³¨æ„åŠ›å›¾ --------------------------
        for idx, am in enumerate(attention_maps):
            try:
                # å¤„ç†ä¸åŒç»´åº¦çš„æ³¨æ„åŠ›å›¾
                am = am.detach().cpu()
                # é™ç»´ï¼šé€šé“å¹³å‡
                if len(am.shape) == 4:  # [B, C, H, W]
                    am = am.squeeze(0)  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
                if len(am.shape) == 3:  # [C, H, W]
                    am = am.mean(dim=0)  # é€šé“å¹³å‡

                # å½’ä¸€åŒ–åˆ°0-1
                am = (am - am.min()) / (am.max() - am.min() + 1e-8)
                # ç¼©æ”¾è‡³åŸå›¾å°ºå¯¸
                am_np = am.numpy()
                am_resized = np.array(Image.fromarray(am_np).resize(image.size, Image.BILINEAR))

                # ç»˜åˆ¶å¹¶ä¿å­˜
                fig, ax = plt.subplots(1, 1, figsize=(8, 8))
                ax.imshow(image)
                ax.imshow(am_resized, cmap='jet', alpha=0.5)
                ax.axis('off')
                plt.tight_layout(pad=0)
                save_path = os.path.join(save_dir, f"attention_{idx}.png")
                plt.savefig(save_path, dpi=150, bbox_inches='tight', pad_inches=0)
                plt.close(fig)

            except Exception as e:
                print(f"âš ï¸  å¤„ç†æ³¨æ„åŠ›å›¾ {idx} å¤±è´¥ï¼š{e}")
                continue

        print(f"âœ… æ³¨æ„åŠ›å›¾å·²ä¿å­˜è‡³ {save_dir}")

    except Exception as e:
        print(f"âš ï¸  æ³¨æ„åŠ›å¯è§†åŒ–å¤±è´¥ï¼š{e}")
    finally:
        # ç§»é™¤é’©å­ï¼Œé¿å…å†…å­˜æ³„æ¼
        for hook in hooks:
            hook.remove()


# -------------------------- ä¸»å‡½æ•° --------------------------
if __name__ == "__main__":
    # åŠ è½½é…ç½®
    config = get_config()

    # åˆå§‹åŒ–YOLOæ¨¡å‹ï¼ˆæ·»åŠ è®¾å¤‡å…¼å®¹ï¼‰
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    yolo = YOLO()
    yolo.device = device
    if hasattr(yolo.model, 'to'):
        yolo.model = yolo.model.to(device)
    print(f"ğŸ”§ æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡ï¼š{device}")

    # é…ç½®å‚æ•°ï¼ˆå…¼å®¹é…ç½®æ–‡ä»¶ï¼Œå¢åŠ é»˜è®¤å€¼ï¼‰
    dir_detect_path = config.get('dir_detect_path', 'VOCdevkit/VOC2026/images')  # å¾…æ£€æµ‹å›¾åƒç›®å½•
    detect_save_path = config.get('detect_save_path', 'auto_annotations')  # æ ‡æ³¨ä¿å­˜ç›®å½•
    vis_attention = config.get('visualize_attention', False)  # æ˜¯å¦å¯è§†åŒ–æ³¨æ„åŠ›
    conf_threshold = config.get('conf_threshold', 0.5)  # æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(dir_detect_path):
        raise FileNotFoundError(f"âŒ æ£€æµ‹ç›®å½•ä¸å­˜åœ¨ï¼š{dir_detect_path}")

    # è·å–å›¾åƒåˆ—è¡¨ï¼ˆè¿‡æ»¤æœ‰æ•ˆæ ¼å¼ï¼‰
    img_exts = ('.bmp', '.dib', '.png', '.jpg', '.jpeg', '.pbm', '.pgm', '.ppm', '.tif', '.tiff')
    img_names = [f for f in os.listdir(dir_detect_path) if f.lower().endswith(img_exts)]

    if not img_names:
        print("âš ï¸  æ£€æµ‹ç›®å½•ä¸‹æ— æœ‰æ•ˆå›¾åƒæ–‡ä»¶")
        exit(0)

    print(f"ğŸ“Š å¼€å§‹å¤„ç† {len(img_names)} å¼ å›¾åƒ...")

    # æ‰¹é‡å¤„ç†å›¾åƒ
    for img_name in tqdm(img_names, desc="è‡ªåŠ¨æ ‡æ³¨è¿›åº¦"):
        try:
            # 1. åŠ è½½å›¾åƒ
            img_path = os.path.join(dir_detect_path, img_name)
            image = Image.open(img_path).convert('RGB')
            img_size = image.size  # (width, height)
            img_name_noext = os.path.splitext(img_name)[0]

            # 2. å¯é€‰ï¼šæ³¨æ„åŠ›å¯è§†åŒ–
            if vis_attention:
                att_save_dir = os.path.join(detect_save_path, "attention_maps", img_name_noext)
                visualize_attention(yolo, image, save_dir=att_save_dir)

            # 3. æ¨¡å‹æ£€æµ‹ï¼ˆå¢åŠ ç½®ä¿¡åº¦è¿‡æ»¤ï¼‰
            boxes = yolo.get_box(image)
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ¡†ï¼ˆå¦‚æœget_boxè¿”å›åŒ…å«ç½®ä¿¡åº¦çš„æ ¼å¼ï¼Œéœ€è°ƒæ•´ï¼‰
            # ç¤ºä¾‹ï¼šå¦‚æœboxesæ ¼å¼ä¸º (label, ymin, xmin, ymax, xmax, conf)
            # boxes = [box for box in boxes if box[-1] >= conf_threshold]

            if not boxes:
                print(f"âš ï¸  {img_name} æœªæ£€æµ‹åˆ°ç›®æ ‡ï¼Œè·³è¿‡æ ‡æ³¨")
                continue

            # 4. ç”ŸæˆYOLOæ ¼å¼TXTæ ‡æ³¨ï¼ˆæ›¿ä»£åŸXMLï¼‰
            generate_yolo_txt(boxes, img_size, detect_save_path, img_name_noext)

        except Exception as e:
            print(f"\nâŒ å¤„ç† {img_name} å¤±è´¥ï¼š{e}")
            continue

    # æœ€ç»ˆç»Ÿè®¡
    generated_txt = [f for f in os.listdir(detect_save_path) if f.endswith('.txt')]
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ˆ æˆåŠŸç”Ÿæˆæ ‡æ³¨ï¼š{len(generated_txt)} ä¸ª")
    print(f"ğŸ’¾ æ ‡æ³¨ä¿å­˜è·¯å¾„ï¼š{detect_save_path}")
    if vis_attention:
        print(f"ğŸ–¼ï¸  æ³¨æ„åŠ›å›¾ä¿å­˜è·¯å¾„ï¼š{os.path.join(detect_save_path, 'attention_maps')}")