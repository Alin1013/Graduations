"""æ‰‹åŠ¿æ£€æµ‹webå¹³å°"""
import os
import time
import cv2
import numpy as np
import torch
from PIL import Image
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
import av
from ultralytics import YOLO
import ssl
from datetime import datetime

# å…¨å±€ç¦ç”¨SSLè¯ä¹¦éªŒè¯ï¼ˆè§£å†³æ¨¡å‹ä¸‹è½½HTTPSé—®é¢˜ï¼‰
ssl._create_default_https_context = ssl._create_unverified_context

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ‰‹åŠ¿æ£€æµ‹å¹³å°",
    page_icon="âœŒï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# WebRTCé…ç½®ï¼ˆå®æ—¶æ‘„åƒå¤´é€šä¿¡ï¼‰
RTC_CONFIGURATION = RTCConfiguration({
    "RTCIceServers": [{
        "urls": ["stun:stun.l.google.com:19302"]
    }]
})

# YOLOv8æ¨¡å‹é…ç½®ï¼ˆåŒ…å«æœ¬åœ°æ¨¡å‹è·¯å¾„å’Œè‡ªå®šä¹‰æƒé‡é€‰é¡¹ï¼‰
# è¯·åœ¨è¿™é‡Œä¿®æ”¹ä¸ºä½ çš„æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
LOCAL_MODEL_PATHS = {
    "yolov8n.pt": "/Users/alin/Graduation_Project/yolov8n.pt",  # æ›¿æ¢ä¸ºå®é™…æœ¬åœ°è·¯å¾„
    "yolov8s.pt": "/Users/alin/Graduation_Project/yolov8s.pt",  # æ›¿æ¢ä¸ºå®é™…æœ¬åœ°è·¯å¾„
    "yolov8m.pt": "/Users/alin/Graduation_Project/yolov8m.pt",  # æ›¿æ¢ä¸ºå®é™…æœ¬åœ°è·¯å¾„
    "yolov8l.pt": "/Users/alin/Graduation_Project/yolov8l.pt",  # æ›¿æ¢ä¸ºå®é™…æœ¬åœ°è·¯å¾„
    "best.pt":"runs/detect/gesture_final_train/weights/best.pt",
}

MODEL_OPTIONS = {
    "yolov8n.pt": {"name": "ç›®æ ‡è¯†åˆ«-Nano (æœ€å¿«)", "local_path": LOCAL_MODEL_PATHS["yolov8n.pt"], "is_custom": False},
    "yolov8s.pt": {"name": "ç›®æ ‡è¯†åˆ«-Small (å¹³è¡¡)", "local_path": LOCAL_MODEL_PATHS["yolov8s.pt"], "is_custom": False},
    "yolov8m.pt": {"name": "ç›®æ ‡è¯†åˆ«-Medium (é«˜ç²¾åº¦)", "local_path": LOCAL_MODEL_PATHS["yolov8m.pt"], "is_custom": False},
    "yolov8l.pt": {"name": "ç›®æ ‡è¯†åˆ«-Large (è¶…é«˜ç²¾åº¦)", "local_path": LOCAL_MODEL_PATHS["yolov8l.pt"], "is_custom": False},
    "custom_weight": {"name": "æ‰‹åŠ¿è¯†åˆ«-Best (è®­ç»ƒæƒé‡)", "local_path": LOCAL_MODEL_PATHS["best.pt"], "is_custom": False},  # è‡ªå®šä¹‰æƒé‡å ä½ç¬¦
}

# æ”¯æŒçš„è¾“å…¥å°ºå¯¸å’Œæ‰‹åŠ¿ç±»åˆ«
INPUT_SHAPES = [640, 1280]
GESTURE_CLASSES = ["one","two_up","two_up_inverted","three","four","fist","palm","ok","peace","loke","dislike","stop","stop_inverted","call","mute","rock","no_gesture"]

# åˆ›å»ºä¸´æ—¶ç›®å½•ï¼ˆå­˜å‚¨ä¸Šä¼ çš„è§†é¢‘/æƒé‡ï¼‰
os.makedirs("temp", exist_ok=True)

# -------------------------- æ¨¡å‹ç›¸å…³å‡½æ•° --------------------------
def check_local_model(model_path):
    """æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if os.path.exists(model_path):
        st.info(f"å·²æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ï¼")
        return True
    else:
        st.error(f"æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
        return False

@st.cache_resource(show_spinner="åŠ è½½æ¨¡å‹ä¸­...")
def load_model(model_key, conf_threshold, nms_threshold, custom_weight_path=None):
    """åŠ è½½YOLOæ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼‰"""
    model_info = MODEL_OPTIONS[model_key]

    # åŠ è½½å®˜æ–¹æ¨¡å‹ï¼ˆæœ¬åœ°è·¯å¾„ï¼‰
    if not model_info["is_custom"]:
        model_path = model_info["local_path"]
        if not check_local_model(model_path):
            return None
    # åŠ è½½è‡ªå®šä¹‰æƒé‡
    else:
        if not custom_weight_path or not os.path.exists(custom_weight_path):
            st.error("è‡ªå®šä¹‰æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼")
            return None
        model_path = custom_weight_path

    try:
        model = YOLO(model_path)
        model.conf = conf_threshold  # ç½®ä¿¡åº¦é˜ˆå€¼
        model.iou = nms_threshold    # NMSé˜ˆå€¼
        return model
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None

# -------------------------- æ£€æµ‹ç›¸å…³å‡½æ•° --------------------------
def detect_image(model, image, input_shape):
    """å•å¼ å›¾åƒæ£€æµ‹"""
    if model is None:
        return None
    try:
        results = model.predict(image, imgsz=input_shape, verbose=False)
        return results[0].plot()  # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œç±»åˆ«
    except Exception as e:
        st.error(f"å›¾åƒæ£€æµ‹å¤±è´¥: {str(e)}")
        return None

class VideoProcessor:
    """å®æ—¶æ‘„åƒå¤´è§†é¢‘å¤„ç†ç±»"""
    def __init__(self, model, input_shape):
        self.model = model
        self.input_shape = input_shape

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        if self.model:
            results = self.model.predict(img, imgsz=self.input_shape, verbose=False)
            img = results[0].plot()
        return av.VideoFrame.from_ndarray(img, format="bgr24")

def calculate_fps(model, input_shape):
    """è®¡ç®—æ¨¡å‹æ¨ç†FPS"""
    if model is None:
        return 0.0
    try:
        test_img = np.zeros((input_shape, input_shape, 3), dtype=np.uint8)
        start_time = time.time()
        # å¤šæ¬¡æ¨ç†å–å¹³å‡
        for _ in range(10):
            model.predict(test_img, imgsz=input_shape, verbose=False)
        elapsed = time.time() - start_time
        return 10 / elapsed
    except Exception as e:
        st.error(f"FPSè®¡ç®—å¤±è´¥: {str(e)}")
        return 0.0

def process_video(model, video_path, input_shape):
    """å¤„ç†ä¸Šä¼ çš„è§†é¢‘å¹¶ä¿å­˜ç»“æœ"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # è¾“å‡ºè§†é¢‘è·¯å¾„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"temp/gesture_detection_{timestamp}.mp4"

    # è§†é¢‘ç¼–ç å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    # å¤„ç†è¿›åº¦æ¡
    progress_bar = st.progress(0)
    frame_idx = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # æ£€æµ‹å¹¶ç»˜åˆ¶ç»“æœ
        results = model.predict(frame, imgsz=input_shape, verbose=False)
        result_frame = results[0].plot()
        out.write(result_frame)

        # æ›´æ–°è¿›åº¦
        frame_idx += 1
        progress_bar.progress(min(frame_idx / frame_count, 1.0))

    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    progress_bar.empty()
    return output_path

# -------------------------- ä¸»åº”ç”¨å‡½æ•° --------------------------
def main():
    st.title("âœŒï¸ æ‰‹åŠ¿æ£€æµ‹å¹³å°")
    st.markdown("åŸºäºYOLOv8çš„å®æ—¶æ‰‹åŠ¿æ£€æµ‹ç³»ç»Ÿ | æ”¯æŒå›¾åƒ/æ‘„åƒå¤´/è§†é¢‘ä¸‰ç§æ£€æµ‹æ¨¡å¼")

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("ğŸ”§ å‚æ•°è®¾ç½®")

        # 1. åº”ç”¨æ¨¡å¼é€‰æ‹©
        app_mode = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½æ¨¡å¼",
            ["å›¾åƒæ£€æµ‹", "å®æ—¶æ‘„åƒå¤´", "è§†é¢‘ä¸Šä¼ ", "æ€§èƒ½æµ‹è¯•", "å…³äº"]
        )

        # 2. æ¨¡å‹è®¾ç½®
        st.subheader("ğŸ“¦ æ¨¡å‹é…ç½®")
        model_key = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            list(MODEL_OPTIONS.keys()),
            format_func=lambda x: MODEL_OPTIONS[x]["name"]
        )

        # è‡ªå®šä¹‰æƒé‡ä¸Šä¼ ï¼ˆä»…å½“é€‰æ‹©è‡ªå®šä¹‰æƒé‡æ—¶æ˜¾ç¤ºï¼‰
        custom_weight_path = None
        if MODEL_OPTIONS[model_key]["is_custom"]:
            st.warning("è¯·ä¸Šä¼ è®­ç»ƒå¥½çš„æ‰‹åŠ¿æ£€æµ‹æƒé‡æ–‡ä»¶ï¼ˆ.ptæ ¼å¼ï¼‰")
            uploaded_weight = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰æƒé‡", type=["pt"])

            if uploaded_weight is not None:
                # ä¿å­˜ä¸Šä¼ çš„æƒé‡åˆ°ä¸´æ—¶æ–‡ä»¶
                custom_weight_path = "temp/custom_best.pt"
                with open(custom_weight_path, "wb") as f:
                    f.write(uploaded_weight.getbuffer())
                st.success("è‡ªå®šä¹‰æƒé‡ä¸Šä¼ æˆåŠŸï¼")
            else:
                # æ£€æŸ¥é»˜è®¤è·¯å¾„æ˜¯å¦æœ‰æƒé‡ï¼ˆå…¼å®¹åŸæœ‰è®­ç»ƒè·¯å¾„ï¼‰
                default_custom_path = "runs/detect/normal_train/weights/best.pt"
                if os.path.exists(default_custom_path):
                    custom_weight_path = default_custom_path
                    st.info(f"æ‰¾åˆ°é»˜è®¤è·¯å¾„æƒé‡ï¼š{default_custom_path}")

        # 3. æ£€æµ‹å‚æ•°
        input_shape = st.selectbox(
            "è¾“å…¥å›¾åƒå°ºå¯¸",
            INPUT_SHAPES,
            format_func=lambda x: f"{x}x{x}"
        )

        conf_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            0.0, 1.0, 0.5, 0.01,
            help="æ£€æµ‹æ¡†ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆå€¼è¶Šé«˜è¶Šä¸¥æ ¼ï¼‰"
        )

        nms_threshold = st.slider(
            "NMSé˜ˆå€¼",
            0.0, 1.0, 0.3, 0.01,
            help="å»é™¤é‡å æ£€æµ‹æ¡†çš„é˜ˆå€¼"
        )

        # 4. åŠ è½½æ¨¡å‹æŒ‰é’®
        st.markdown("---")
        load_btn = st.button("ğŸš€ åŠ è½½æ¨¡å‹")
        if load_btn:
            with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
                # åŠ è½½æ¨¡å‹ï¼ˆæ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç±»å‹ä¼ å…¥ä¸åŒå‚æ•°ï¼‰
                if MODEL_OPTIONS[model_key]["is_custom"]:
                    model = load_model(
                        model_key,
                        conf_threshold,
                        nms_threshold,
                        custom_weight_path=custom_weight_path
                    )
                else:
                    model = load_model(
                        model_key,
                        conf_threshold,
                        nms_threshold
                    )

                if model:
                    st.session_state["model"] = model
                    st.session_state["model_info"] = MODEL_OPTIONS[model_key]
                    st.success(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼š{MODEL_OPTIONS[model_key]['name']}")
                else:
                    st.session_state["model"] = None
                    st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ï¼")

        # 5. æ”¯æŒçš„æ‰‹åŠ¿
        st.markdown("---")
        st.subheader("ğŸ–ï¸ æ”¯æŒæ‰‹åŠ¿")
        st.write(" | ".join(GESTURE_CLASSES))

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½ï¼ˆé™¤"å…³äº"æ¨¡å¼å¤–ï¼‰
    model = st.session_state.get("model")
    if model is None and app_mode not in ["å…³äº"]:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é€‰æ‹©æ¨¡å‹å¹¶ç‚¹å‡»'åŠ è½½æ¨¡å‹'æŒ‰é’®")
        return

    # -------------------------- åŠŸèƒ½æ¨¡å¼å®ç° --------------------------
    if app_mode == "å›¾åƒæ£€æµ‹":
        st.subheader("ğŸ“· å›¾åƒæ£€æµ‹")
        st.write("ä¸Šä¼ åŒ…å«æ‰‹åŠ¿çš„å›¾åƒï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å¹¶æ ‡è®°ç±»åˆ«")

        uploaded_file = st.file_uploader("é€‰æ‹©å›¾åƒæ–‡ä»¶", type=["jpg", "jpeg", "png"])
        if uploaded_file is not None:
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            image = Image.open(uploaded_file)
            col1, col2 = st.columns(2)

            with col1:
                st.info("åŸå§‹å›¾åƒ")
                st.image(image, use_column_width=True)

            # æ£€æµ‹æŒ‰é’®
            if st.button("å¼€å§‹æ£€æµ‹"):
                with st.spinner("æ­£åœ¨å¤„ç†å›¾åƒ..."):
                    img_array = np.array(image)
                    result_img = detect_image(model, img_array, input_shape)

                    with col2:
                        st.success("æ£€æµ‹ç»“æœ")
                        if result_img is not None:
                            st.image(result_img, use_column_width=True)

    elif app_mode == "å®æ—¶æ‘„åƒå¤´":
        st.subheader("ğŸ“¹ å®æ—¶æ‘„åƒå¤´æ£€æµ‹")
        st.info("ç‚¹å‡»ä¸‹æ–¹åŒºåŸŸå¯åŠ¨æ‘„åƒå¤´ï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€æˆäºˆæµè§ˆå™¨æƒé™ï¼‰")

        if model:
            webrtc_streamer(
                key="gesture-detection",
                mode=WebRtcMode.SENDRECV,
                rtc_configuration=RTC_CONFIGURATION,
                video_processor_factory=lambda: VideoProcessor(model, input_shape),
                media_stream_constraints={"video": True, "audio": False},
                async_processing=True,
            )

    elif app_mode == "è§†é¢‘ä¸Šä¼ ":
        st.subheader("ğŸ¥ è§†é¢‘ä¸Šä¼ æ£€æµ‹")
        st.warning("æç¤ºï¼šè§†é¢‘å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œè®¾å¤‡æ€§èƒ½ï¼Œå»ºè®®å…ˆæµ‹è¯•çŸ­è§†é¢‘ï¼ˆ<1åˆ†é’Ÿï¼‰")

        uploaded_video = st.file_uploader("é€‰æ‹©è§†é¢‘æ–‡ä»¶", type=["mp4", "mov", "avi"])
        if uploaded_video is not None:
            # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_video_path = "temp/uploaded_video.mp4"
            with open(temp_video_path, "wb") as f:
                f.write(uploaded_video.read())

            # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
            cap = cv2.VideoCapture(temp_video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            st.info(f"è§†é¢‘ä¿¡æ¯ï¼š{fps:.1f} FPS | {frame_count} å¸§ | æ—¶é•¿ï¼š{duration:.1f} ç§’")
            cap.release()

            # æ˜¾ç¤ºåŸå§‹è§†é¢‘é¢„è§ˆ
            st.subheader("åŸå§‹è§†é¢‘é¢„è§ˆ")
            st.video(temp_video_path)

            # å¤„ç†è§†é¢‘æŒ‰é’®
            if st.button("å¼€å§‹å¤„ç†è§†é¢‘"):
                with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘..."):
                    output_path = process_video(model, temp_video_path, input_shape)
                    st.success("âœ… è§†é¢‘å¤„ç†å®Œæˆï¼")

                    # æ˜¾ç¤ºå¤„ç†ç»“æœ
                    st.subheader("å¤„ç†ç»“æœé¢„è§ˆ")
                    st.video(output_path)

                    # ä¸‹è½½æŒ‰é’®
                    with open(output_path, "rb") as f:
                        st.download_button(
                            label="ä¸‹è½½å¤„ç†åçš„è§†é¢‘",
                            data=f,
                            file_name=f"gesture_detection_{datetime.now().strftime('%Y%m%d')}.mp4",
                            mime="video/mp4"
                        )

    elif app_mode == "æ€§èƒ½æµ‹è¯•":
        st.subheader("âš¡ æ¨¡å‹æ€§èƒ½æµ‹è¯•")
        st.write("æµ‹è¯•å½“å‰æ¨¡å‹åœ¨è®¾å¤‡ä¸Šçš„æ¨ç†é€Ÿåº¦ï¼ˆFPSï¼‰ï¼Œç»“æœä»…ä¾›å‚è€ƒ")

        if st.button("å¼€å§‹æµ‹è¯•FPS"):
            with st.spinner("æ­£åœ¨æµ‹è¯•æ€§èƒ½..."):
                fps = calculate_fps(model, input_shape)
                st.success(f"æµ‹è¯•å®Œæˆï¼å¹³å‡FPSï¼š{fps:.2f} å¸§/ç§’")

                # æ€§èƒ½è¯„ä¼°
                if fps < 10:
                    st.warning("æ€§èƒ½è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ï¼š\n1. é€‰æ‹©æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚yolov8nï¼‰\n2. é™ä½è¾“å…¥å°ºå¯¸ï¼ˆå¦‚640x640ï¼‰\n3. ä½¿ç”¨GPUåŠ é€Ÿ")
                elif fps < 25:
                    st.info("æ€§èƒ½ä¸­ç­‰ï¼Œå¯æ»¡è¶³åŸºæœ¬å®æ—¶æ£€æµ‹éœ€æ±‚")
                else:
                    st.success("æ€§èƒ½ä¼˜å¼‚ï¼Œé€‚åˆé«˜è´¨é‡å®æ—¶æ£€æµ‹ï¼")

    elif app_mode == "å…³äº":
        st.subheader("ğŸ“‹ å…³äºæœ¬å¹³å°")
        st.markdown("""
        ### æ‰‹åŠ¿æ£€æµ‹å¹³å°ï¼ˆåŸºäºYOLOv8ï¼‰
        
        **æ ¸å¿ƒåŠŸèƒ½**ï¼š
        - å›¾åƒæ£€æµ‹ï¼šå•å¼ å›¾åƒæ‰‹åŠ¿è¯†åˆ«
        - å®æ—¶æ‘„åƒå¤´ï¼šæµè§ˆå™¨ç«¯å®æ—¶æ‰‹åŠ¿è·Ÿè¸ª
        - è§†é¢‘ä¸Šä¼ ï¼šæ‰¹é‡å¤„ç†è§†é¢‘å¹¶ä¿å­˜æ£€æµ‹ç»“æœ
        - æ€§èƒ½æµ‹è¯•ï¼šè¯„ä¼°æ¨¡å‹åœ¨å½“å‰è®¾å¤‡çš„è¿è¡Œé€Ÿåº¦
        
        **æŠ€æœ¯æ ˆ**ï¼š
        - ç›®æ ‡æ£€æµ‹ï¼šYOLOv8ï¼ˆUltralyticsï¼‰
        - Webæ¡†æ¶ï¼šStreamlit
        - å®æ—¶é€šä¿¡ï¼šWebRTC
        - å›¾åƒå¤„ç†ï¼šOpenCVã€NumPy
        
        **ä½¿ç”¨æç¤º**ï¼š
        1. å»ºè®®åœ¨å…‰çº¿å……è¶³çš„ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œæé«˜æ£€æµ‹å‡†ç¡®ç‡
        2. æ‰‹åŠ¿å°½é‡æ¸…æ™°å¯è§ï¼Œé¿å…å¤æ‚èƒŒæ™¯å¹²æ‰°
        3. è‡ªå®šä¹‰æƒé‡éœ€ä½¿ç”¨YOLOv8è®­ç»ƒçš„æ‰‹åŠ¿æ£€æµ‹æ¨¡å‹ï¼ˆ8ç±»æ‰‹åŠ¿ï¼‰
        4. å®æ—¶æ£€æµ‹å»ºè®®FPSâ‰¥15ï¼Œå¯é€šè¿‡è°ƒæ•´æ¨¡å‹å’Œè¾“å…¥å°ºå¯¸ä¼˜åŒ–
        """)

if __name__ == "__main__":
    main()